<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="Virigl,mrchan3668@gmail.com"><title>《集体编程智慧》—— 4.搜索与排名 · Virgil Chan</title><meta name="description" content="以下代码完整步骤在 Github 上可看
介绍《集体编程智慧》是一本介绍机器学习与计算统计的书，相当硬核，实际编程占了很大的篇幅。书里专门讲述如何挖掘和分析 Web 上的数据和资源，如何分析和获得更好的用户体验。包括协作过滤技术（实现关联产品推荐功能）、集群数据分析（在大规模数据集中发掘相似的数据子"><meta name="keywords" content="HTML,CSS,JavaScript,Vue,AngularJS,WebPack,UnderScore,System,Raspberry,Tool,Linux,WordPress,NodeJS,MongoDB,Git,Python"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><link rel="manifest" href="/manifest.json"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/favicon.png" style="width:127px;"><h3 title><a href="/">Virgil Chan</a></h3><div class="description"><p>间歇性凌云壮志，持续性混吃等死</p></div></div></div><ul class="social-links"><li><a href="http://www.feed43.com/6708067855351261.xml"><i class="fa fa-rss"></i></a></li><li><a href="http://weibo.com/1953548815"><i class="fa fa-weibo"></i></a></li><li><a href="http://github.com/pansy-cx"><i class="fa fa-github"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai </a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li></div><div class="information"><div class="back_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li></div><div class="avatar"><img src="/images/favicon.png"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>《集体编程智慧》—— 4.搜索与排名</a></h3></div><div class="post-content"><p>以下代码完整步骤在 <a href="https://github.com/pansy-cx/Programming-Collective-Intelligence/tree/master/4.%20Searching%20and%20Ranking" target="_blank" rel="noopener">Github</a> 上可看</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>《集体编程智慧》是一本介绍机器学习与计算统计的书，相当硬核，实际编程占了很大的篇幅。书里专门讲述如何挖掘和分析 Web 上的数据和资源，如何分析和获得更好的用户体验。包括协作过滤技术（实现关联产品推荐功能）、集群数据分析（在大规模数据集中发掘相似的数据子集）、搜索引擎核心技术（爬虫、索引、查询引擎、PageRank算法等）、搜索海量信息并进行分析统计得出结论的优化算法、贝叶斯过滤技术（垃圾邮件过滤、文本过滤）、用决策树技术实现预测和决策建模功能、社交网络的信息匹配技术、机器学习和人工智能应用等。</p>
<p>本文总结的是《集体编程》第四章的内容，搜索引擎与排名。虽然是第四章，却是《集体智慧编程》系列的第一弹，之前看的零零散散，不成体系，如今打算拿出时间好好的学一学，虽然很可能又被我鸽掉，但至少这是个好的开始，不是么？</p>
<h3 id="搜索引擎的组成"><a href="#搜索引擎的组成" class="headerlink" title="搜索引擎的组成"></a>搜索引擎的组成</h3><p>建立搜索引擎首要步骤是建立一个搜索文档的方法，即网页的抓取。从一小组网页开始，再根据网页内的链接逐步追踪其他的网页。</p>
<p>搜集完文档后，对文档建立索引，表中包含文档所有不同单词的位置信息，最后通过查询返回一个经过排序的文档列表。根据不同的度量方法可以改变网页排名次序。</p>
<h3 id="爬虫程序"><a href="#爬虫程序" class="headerlink" title="爬虫程序"></a>爬虫程序</h3><p>首先是建立搜索文档，假定有一组网页链接，如何建立搜索文档？首先需要Python把网页加载下来，遍历网页内的链接内容，如此循环。然后需要将网页内容给分割成单词或词语，将单词和位置存到数据库里储存。</p>
<h5 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h5><p>requests 是一个Python网络库，书里用的是urlib2，由于是几年前的书了，在对 HTTPS 处理有些问题，这里就不表了，用 requests 也是一样的。要解决 HTTPS 的问题，只需要修改一下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> requests.packages.urllib3.util.ssl_</span><br><span class="line">requests.packages.urllib3.util.ssl_.DEFAULT_CIPHERS = <span class="string">'ALL'</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">c = requests.get(<span class="string">'https://idmrchan.com'</span>)</span><br><span class="line">soup = BeautifulSoup(c.text)</span><br><span class="line">links = soup(<span class="string">'a'</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    <span class="keyword">if</span> (<span class="string">'href'</span> <span class="keyword">in</span> dict(link.attrs)):</span><br><span class="line">        url = urljoin(page, link[<span class="string">'href'</span>])</span><br><span class="line">        <span class="keyword">if</span> url.find(<span class="string">"'"</span>) != <span class="number">-1</span>: <span class="keyword">continue</span></span><br><span class="line">        url = url.split(<span class="string">'#'</span>)[<span class="number">0</span>] <span class="comment"># 去掉位置部分</span></span><br><span class="line">        <span class="keyword">if</span> url[<span class="number">0</span>:<span class="number">4</span>] == <span class="string">'http'</span>:</span><br><span class="line">            <span class="comment"># 对获得的 url 进一步遍历</span></span><br></pre></td></tr></table></figure>
<h5 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h5><p>首先将HTML里的文字提取出来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gettextonly</span><span class="params">(soup)</span>:</span></span><br><span class="line">    v = soup.string</span><br><span class="line">    <span class="keyword">if</span> v == <span class="literal">None</span>:</span><br><span class="line">        c = soup.contents</span><br><span class="line">        resulttext = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> c:</span><br><span class="line">            subtext = self.gettextonly(t)</span><br><span class="line">            resulttext += subtext + <span class="string">'\n'</span></span><br><span class="line">        <span class="keyword">return</span> resulttext</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> v.strip()</span><br></pre></td></tr></table></figure>
<p>处理英文字符，中文分割用 <a href="https://github.com/fxsjy/jieba" target="_blank">jieba</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取英文字符，如 vue, vue-cli, C++, don't ......</span></span><br><span class="line">l = re.findall(<span class="string">r'[\w\-?\+*\'?]+'</span>, text)</span><br><span class="line"><span class="comment"># 去除英文字符和空格</span></span><br><span class="line">text = re.sub(<span class="string">r'[\w\-?\+*\'?]+|\s'</span>, <span class="string">''</span>, text)</span><br><span class="line"><span class="comment"># 用 jieba 分割中文</span></span><br><span class="line">seg_list = jieba.cut(text, cut_all=<span class="literal">False</span>, HMM=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> seg <span class="keyword">in</span> seg_list:</span><br><span class="line">    l.append(seg)</span><br></pre></td></tr></table></figure>
<h5 id="建立索引"><a href="#建立索引" class="headerlink" title="建立索引"></a>建立索引</h5><p>使用 sqlite3 建立数据库，SQLite 是一个嵌入式数据库，将整个数据库存入了一个文件之中，很方便。<a href="http://www.runoob.com/sqlite/sqlite-tutorial.html" target="_blank">菜鸟教程 SQLite</a></p>
<p>我们用3个表来储存，一个为 urllist，储存 url 链接，一个为 wordlist 储存单词表和，一个 wordlocation 储存链接 id，单词 id 和单词在网页的位置</p>
<p>创建数据表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">con = sqlite.connect(dbname)</span><br><span class="line">con.execute(<span class="string">'create table urllist(url)'</span>)</span><br><span class="line">con.execute(<span class="string">'create table wordlist(word)'</span>)</span><br><span class="line">con.execute(<span class="string">'create table wordlocation(urlid,wordid,location)'</span>)</span><br></pre></td></tr></table></figure>
<p>添加函数，用于获取与插入条目</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getentryid</span><span class="params">(table, field, value)</span>:</span></span><br><span class="line">    <span class="comment"># 查询 id</span></span><br><span class="line">    cur = con.execute(</span><br><span class="line">        <span class="string">"select rowid from &#123;&#125; where &#123;&#125;=?"</span>.format(table,field), (value,))</span><br><span class="line">    res = cur.fetchone()</span><br><span class="line">    <span class="comment"># 如果不存在，则插入</span></span><br><span class="line">    <span class="keyword">if</span> res == <span class="literal">None</span>:</span><br><span class="line">        cur = self.con.execute(</span><br><span class="line">            <span class="string">"insert into &#123;&#125; (&#123;&#125;) values (?)"</span>.format(table,field), (value,))</span><br><span class="line">        <span class="keyword">return</span> cur.lastrowid</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> res[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>为每个网页建立搜索引擎</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addtoindex</span><span class="params">(url, soup)</span>:</span></span><br><span class="line">    <span class="comment"># soup 为去除 HTML 的文字</span></span><br><span class="line">    <span class="comment"># ... 经如上步骤处理得到 words，文字库</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 得到url的id，没有则插入并返回 id</span></span><br><span class="line">    urlid = getentryid(<span class="string">'urllist'</span>, <span class="string">'url'</span>, url)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将每个单词与该url关联</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words)):</span><br><span class="line">        word = words[i]</span><br><span class="line">        wordid = getentryid(<span class="string">'wordlist'</span>, <span class="string">'word'</span>, word)</span><br><span class="line">        con.execute(<span class="string">"insert into wordlocation(urlid, wordid, location) values (%d, %d, %d)"</span> % (urlid, wordid, i))</span><br></pre></td></tr></table></figure>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>我们先建立一个简单的搜索方法，允许多次搜索，如 getmatchrows(‘vue webpack’)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">con = sqlite.connect(dbname)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getmatchrows</span><span class="params">(q)</span>:</span></span><br><span class="line">    <span class="comment"># 构造查询的字符串</span></span><br><span class="line">    fieldlist = <span class="string">'w0.urlid'</span></span><br><span class="line">    tablelist = <span class="string">''</span></span><br><span class="line">    clauselist = <span class="string">''</span></span><br><span class="line">    wordids = []</span><br><span class="line">    <span class="comment"># 根据空格拆分单词</span></span><br><span class="line">    words = q.split(<span class="string">' '</span>)</span><br><span class="line">    tablenumber = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="comment"># 获取单词 id</span></span><br><span class="line">        wordrow = con.execute(</span><br><span class="line">            <span class="string">"select rowid from wordlist where word='%s'"</span> % word).fetchone()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> wordrow != <span class="literal">None</span>:</span><br><span class="line">            wordid = wordrow[<span class="number">0</span>]</span><br><span class="line">            wordids.append(wordid)</span><br><span class="line">            <span class="keyword">if</span> tablenumber &gt; <span class="number">0</span>:</span><br><span class="line">                tablelist += <span class="string">','</span></span><br><span class="line">                clauselist += <span class="string">' and '</span></span><br><span class="line">                clauselist += <span class="string">'w%d.urlid=w%d.urlid and '</span> % (tablenumber<span class="number">-1</span>, tablenumber)</span><br><span class="line"></span><br><span class="line">            fieldlist += <span class="string">',w%d.location'</span> % tablenumber</span><br><span class="line">            tablelist += <span class="string">'wordlocation w%d'</span> % tablenumber</span><br><span class="line">            clauselist += <span class="string">'w%d.wordid=%d'</span> % (tablenumber,wordid)</span><br><span class="line">            tablenumber += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据各个分组，建立查询</span></span><br><span class="line">    fullquery = <span class="string">'select %s from %s where %s'</span> % (fieldlist, tablelist, clauselist)</span><br><span class="line">    cur = con.execute(fullquery)</span><br><span class="line">    rows = [row <span class="keyword">for</span> row <span class="keyword">in</span> cur]</span><br><span class="line">    <span class="keyword">return</span> rows,wordids</span><br></pre></td></tr></table></figure>
<p>这个程序看起来复杂，可以将 fullquery 输出出来看看，形如</p>
<pre><code>select w0.urlid,w0.location,w1.location from wordlocation w0,wordlocation w1 where w0.wordid=413 and w0.urlid=w1.urlid and w1.wordid=1295

select x from wordlocation w0, wordlocation w1 
</code></pre><p>将wordlocation进行两次对比</p>
<pre><code>select x from w0,w1 where w0.wordid=413 and w0.urlid=w1.urlid and w1.wordid=1295
</code></pre><p>419 是 vue 单词的位置，1295 是 webpack 单词的位置，需要匹配同一个 urlid，即同时出现了 vue 和 webpack 的网页id</p>
<pre><code>select w0.urlid,w0.location,w1.location
</code></pre><p>输出 urlid | vue 单词位置 | webpack 单词位置</p>
<h5 id="排名"><a href="#排名" class="headerlink" title="排名"></a>排名</h5><p>以上输出的结果只是根据检索时的顺序，而我们需要根据相关性来对检索结果进行排名，包括以下三种方法。</p>
<ol>
<li>单词频度<br>根据位于查询条件中的单词在文档中出现的次数</li>
<li>文档位置<br>文档主题有可能会靠近文档的开始处。实际上搜索引擎会根据网页结构来判断权重，比如 <code>&lt;h1&gt;</code> 权重就比 <code>&lt;p&gt;</code> 来的大</li>
<li>单词距离<br>如果查询条件中有多个单词，则它们在文档中出现的位置应该靠的很近</li>
<li>利用外部回指链接<br>外部回指链接是指在其他网页指向该网页的数目</li>
</ol>
<h5 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h5><p>PageRank 算法 是 Google 发明的，其理论为，设指向 A 链接的有 B C D 三个链接，B C D 的 PageRank 值分别为 PR(B) PR(C) PR(D)，B C D 三个网页的链接分别有 link(B) link(C) link(D)，则 A 的 PageRank 是多少：</p>
<blockquote>
<p>PR(A) = 0.15 + 0.85 * (PR(B)/link(B) + PR(C)/link(C) + PR(D)/link(D))</p>
</blockquote>
<p>0.15 为最小值，0.85 为阻尼系数，用以指示用户持续点击每个链接的概率</p>
<p>此时有个问题，B C D 的 PageRank 怎么算出来的？</p>
<p>解决这一问题的方法是将所有 PageRank 设置为 1，然后反复计算，迭代若干次后 PageRank 值就会接近于真实值。</p>
<p>代码就不放出来了，可自行在 Github 上查看</p>
<h3 id="从点击行为中学习"><a href="#从点击行为中学习" class="headerlink" title="从点击行为中学习"></a>从点击行为中学习</h3><p>根据用户点击抉择来训练模型</p>
<h5 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h5><p>模型需要用到神经网络，以一组节点（神经元）构成，彼此之间相连接，被称为多层感知机（multilayer perceptron, MLP）网络。其第一层神经元接收输入，本例中指用户输入的单词，最后一层输出结果，本例中即返回不同 URL 的权重。</p>
<h5 id="设计数据库"><a href="#设计数据库" class="headerlink" title="设计数据库"></a>设计数据库</h5><p>数据库分为3层，一层为中间的隐藏层，<code>hiddennode(create_key)</code>，输入层为单词与隐藏层之间的连接状态表 <code>wordhidden(fromid,toid,strength)</code>，输出层为隐藏层与输出链接之间的关系表 <code>hiddenurl(fromid,toid,strength)</code></p>
<h5 id="训练实验"><a href="#训练实验" class="headerlink" title="训练实验"></a>训练实验</h5><p>接下来我们模拟用户输入与选择 url，算法根据输入的值更新权重，其中用到了 tanh 函数与反向传播法，具体算法在 <a href="https://github.com/pansy-cx/Programming-Collective-Intelligence/blob/master/4.%20Searching%20and%20Ranking/nn.py" target="_blank">nn.py</a>，这里就不赘述。</p>
<hr>
<p>总之，本章讲了如何使用 SQLite 建立数据库储存信息，爬取网页链接，建立词库。进行多词搜索，并且使用单词频度，相关性，用户点击抉择等来对链接进行排名。</p>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2018-06-10</span><i class="fa fa-tag"></i><a class="tag" href="/tags/Python/" title="Python">Python </a><a class="tag" href="/tags/机器学习/" title="机器学习">机器学习 </a></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" href="http://twitter.com/home?status=,http://idmrchan.com/2018/06/10/searching-and-ranking/,Virgil Chan,《集体编程智慧》—— 4.搜索与排名,;"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/2018/06/27/machine-optimization/" title="《集体编程智慧》—— 5.优化">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/2018/05/13/npm-customize-and-httpservice/" title="自定义 npm 和使用 json-server 进行前端 mock 数据">下一篇</a></li></ul></div></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>